## Hi there ğŸ‘‹

# ğŸš€ vivo Camera Research Lab

**vivoå½±åƒç®—æ³•ç ”ç©¶éƒ¨å­¦æœ¯åˆ›æ–°å®éªŒå®¤**  
æ¢ç´¢ç§»åŠ¨å½±åƒï¼Œè®¡ç®—æ‘„å½±ï¼Œå†…å®¹ç”Ÿæˆï¼Œagent, å¤§æ¨¡å‹ç­‰å‰æ²¿æŠ€æœ¯ã€‚

---

## ğŸŒŸ é¡¹ç›®äº®ç‚¹
**[ICML_2025]** [Learning Adaptive Lighting via Channel-Aware Guidance](https://arxiv.org/abs/2412.01493) \
Qirui Yang, Peng-Tao Jiang, Hao Zhang, Jinwei Chen, Bo Li, Huanjing Yue, Jingyu Yang \
[![arXiv](https://img.shields.io/badge/arXiv-2412.01493-b31b1b.svg)](https://arxiv.org/abs/2412.01493)
[![GitHub](https://img.shields.io/badge/GitHub-Code-E0E0E0?logo=github)](https://xxxxxx2025.github.io/LALNet/)

**[ICLR_2025]** [High-Precision Dichotomous Image Segmentation via Probing Diffusion Capacity](https://arxiv.org/abs/2410.10105) \
Qian Yu, Peng-Tao Jiang, Hao Zhang, Jinwei Chen, Bo Li, Lihe Zhang, Huchuan Lu \
[![arXiv](https://img.shields.io/badge/arXiv-2410.10105-b31b1b.svg)](https://arxiv.org/abs/2410.10105)
[![GitHub](https://img.shields.io/badge/GitHub-Code-E0E0E0?logo=github)](https://github.com/qianyu-dlut/diffdis)

**[ICLR_2025]** [Multi-Task Dense Predictions via Unleashing the Power of Diffusion](https://openreview.net/forum?id=TzdTRC85SQ&referrer=%5Bthe%20profile%20of%20Peng-Tao%20Jiang%5D(%2Fprofile%3Fid%3D~Peng-Tao_Jiang1)) \
Yuqi Yang, Peng-Tao Jiang, Qibin Hou, Hao Zhang, Jinwei Chen, Bo Li \
[![GitHub](https://img.shields.io/badge/GitHub-Code-E0E0E0?logo=github)](https://github.com/YuqiYang213/TaskDiffusion)

**[AAAI 2025]** [Advancing Comprehensive Aesthetic Insight with Multi-Scale Text-Guided Self-Supervised Learning](https://arxiv.org/abs/2412.11952) \
Yuti Liu, Shice Liu, Junyuan Gao, Peng-Tao Jiang, Hao Zhang, Jinwei Chen, Bo Li \
[![arXiv](https://img.shields.io/badge/arXiv-2412.11952-b31b1b.svg)](https://arxiv.org/abs/2412.11952)

**[AAAI 2025 Oral]** [Boosting Vision State Space Model with Fractal Scanning](https://arxiv.org/abs/2405.14480) \
Haoke Xiao, Lv Tang, Peng-Tao Jiang, Hao Zhang, Jinwei Chen, Bo Li \
[![arXiv](https://img.shields.io/badge/arXiv-2405.14480-b31b1b.svg)](https://arxiv.org/abs/2405.14480)
[![GitHub](https://img.shields.io/badge/GitHub-Code-E0E0E0?logo=github)](https://github.com/hkxiao/Fractal-Mamba)

**[IJCV 2024]** [Towards Training-Free Open-World Segmentation via Image Prompt Foundation Models](https://arxiv.org/abs/2310.10912) \
Lv Tang, Peng-Tao Jiang, Hao-Ke Xiao, Bo Li \
[![arXiv](https://img.shields.io/badge/arXiv-2310.10912-b31b1b.svg)](https://arxiv.org/abs/2310.10912)
[![GitHub](https://img.shields.io/badge/GitHub-Code-E0E0E0?logo=github)](https://github.com/luckybird1994/ipseg)

**[NeurIPS 2024]** [Unsupervised Modality Adaptation with Text-to-Image Diffusion Models for Semantic Segmentation](https://arxiv.org/abs/2410.21708) \
Ruihao Xia, Yu Liang, Peng-Tao Jiang, Hao Zhang, Bo Li, Yang Tang, Pan Zhou \
[![arXiv](https://img.shields.io/badge/arXiv-2310.10912-b31b1b.svg)](https://arxiv.org/abs/2410.21708)
[![GitHub](https://img.shields.io/badge/GitHub-Code-E0E0E0?logo=github)](https://github.com/XiaRho/MADM)

**[MM 2024]** [Non-uniform Timestep Sampling: Towards Faster Diffusion Model Training](https://dl.acm.org/doi/10.1145/3664647.3680912) \
Tianyi Zheng, Cong Geng, Peng-Tao Jiang, Ben Wan, Hao Zhang, Jinwei Chen, Jia Wang, Bo Li 

**[MM 2024]** [Chain of visual perception: Harnessing multimodal large language models for zero-shot camouflaged object detection](https://arxiv.org/abs/2311.11273) \
Lv Tang, Peng-Tao Jiang, Zhihao Shen, Hao Zhang, Jinwei Chen, Bo Li \
[![arXiv](https://img.shields.io/badge/arXiv-2311.11273-b31b1b.svg)](https://arxiv.org/abs/2311.11273)

**[ECCV 2024]** [FreeDiff: Progressive Frequency Truncation for Image Editing with Diffusion Models](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00328.pdf) \
Jinfeng Liu, Lingtong Kong, Bo Li, Zerong Wang, Hong Gu, Jinwei Chen \
[![arXiv](https://img.shields.io/badge/arXiv-2403.17749-b31b1b.svg)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00328.pdf)
[![GitHub](https://img.shields.io/badge/GitHub-Code-E0E0E0?logo=github)](https://github.com/thermal-dynamics/freediff)

**[ECCV 2024]** [Mono-ViFI: A Unified Learning Framework for Self-supervised Single- and Multi-frame Monocular Depth Estimation](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00328.pdf) \
Jinfeng Liu, Lingtong Kong, Bo Li, Zerong Wang, Hong Gu, Jinwei Chen \
[![arXiv](https://img.shields.io/badge/arXiv-2403.17749-b31b1b.svg)](https://arxiv.org/abs/2407.14126)
[![GitHub](https://img.shields.io/badge/GitHub-Code-E0E0E0?logo=github)](https://github.com/LiuJF1226/Mono-ViFI)

**[ECCV 2024]** [SAFNet: Selective Alignment Fusion Network for Efficient HDR Imaging](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00328.pdf) \
Lingtong Kong, Bo Li, Yike Xiong, Hao Zhang, Hong Gu, and Jinwei Chen \
[![arXiv](https://img.shields.io/badge/arXiv-2403.17749-b31b1b.svg)](https://arxiv.org/abs/2407.16308)
[![GitHub](https://img.shields.io/badge/GitHub-Code-E0E0E0?logo=github)](https://github.com/ltkong218/SAFNet)

**[ECCV 2024]** [Beta-tuned timestep diffusion model](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00328.pdf) \
Tianyi Zheng, Peng-Tao Jiang, Ben Wan, Hao Zhang, Jinwei Chen, Jia Wang, Bo Li \
[![arXiv](https://img.shields.io/badge/arXiv-2403.17749-b31b1b.svg)](https://eccv.ecva.net/virtual/2024/poster/1430)

**[CVPR 2024]** [Multi-Task Dense Prediction via Mixture of Low-Rank Experts](https://arxiv.org/abs/2403.17749) \
Yuqi Yang, Peng-Tao Jiang, Qibin Hou, Hao Zhang, Jinwei Chen, Bo Li \
[![arXiv](https://img.shields.io/badge/arXiv-2403.17749-b31b1b.svg)](https://arxiv.org/abs/2403.17749)
[![GitHub](https://img.shields.io/badge/GitHub-Code-E0E0E0?logo=github)](https://github.com/YuqiYang213/MLoRE)

**[CVPR 2024]** [Revisiting single image reflection removal in the wild](https://arxiv.org/abs/2311.17320) \
Yurui Zhu, Xueyang Fu, Peng-Tao Jiang, Hao Zhang, Qibin Sun, Jinwei Chen, Zheng-Jun Zha, Bo Li \
[![arXiv](https://img.shields.io/badge/arXiv-2311.17320-b31b1b.svg)](https://arxiv.org/abs/2311.17320)
[![GitHub](https://img.shields.io/badge/GitHub-Code-E0E0E0?logo=github)](https://github.com/zhuyr97/Reflection_RemoVal_CVPR2024)

**[CVPR 2024]** [ASAM: Boosting Segment Anything Model with Adversarial Tuning](https://arxiv.org/abs/2405.00256) \
Bo Li, Haoke Xiao, Lv Tang \
[![arXiv](https://img.shields.io/badge/arXiv-2311.17320-b31b1b.svg)](https://arxiv.org/abs/2405.00256)
[![GitHub](https://img.shields.io/badge/GitHub-Code-E0E0E0?logo=github)](https://github.com/luckybird1994/ASAM)




---


## ğŸ“Œ æ ¸å¿ƒæ–¹å‘
- ğŸ§  å›¾åƒè§†é¢‘ç”ŸæˆæŠ€æœ¯  
- ğŸ‘ï¸ ç§»åŠ¨å›¾åƒç”»è´¨å¢å¼º  
- ğŸ“Š åœºæ™¯æ„ŸçŸ¥ä¸ç†è§£
- ğŸ§¬ ç¾å­¦è¯„ä»·
- ğŸ“ˆ 

---

## ğŸ“¬ è”ç³»æˆ‘ä»¬
- **é‚®ç®±**: {pt.jiang, libra}@vivo.com  
- **å®˜ç½‘**: [vivo Camera Research Lab](https://blueimage.vivo.com/#/research)  
- **å¾®ä¿¡å…¬ä¼—å·**: æ•¬è¯·æœŸå¾… (æ‰«ç å…³æ³¨)  

---

## ğŸ“œ å¼€æºåè®®
æ‰€æœ‰é¡¹ç›®é»˜è®¤é‡‡ç”¨ [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0)ï¼Œè¯¦è§å„ä»“åº“çš„ `LICENSE` æ–‡ä»¶ã€‚

---
